{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.14"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"4b18175c-512d-403c-bb19-5cd3f992946e","cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport torch\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import pairwise_distances\nfrom scipy.stats import pearsonr, spearmanr, f_oneway\nfrom sklearn.linear_model import LinearRegression, LogisticRegression\nfrom sklearn.metrics import r2_score, accuracy_score\n\n# ==================================================\n# CONFIGURATION – CHANGE THIS FOR EACH EXPERIMENT\n# ==================================================\nmodel_name = \"qnn_q14_l12_b64_acc2_s42_20260228_115810_best\"   # your saved model name\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Analyzing experiment: {model_name}\")\n\n# Load the saved data\nembeddings = np.load(f\"{model_name}_embeddings.npz\")\ntrain_emb = embeddings['train_emb']\nval_emb   = embeddings['val_emb']\ntest_emb  = embeddings['test_emb']\n\n# Combine all embeddings (full dataset)\nquantum_embeddings = np.vstack([train_emb, val_emb, test_emb])\nprint(f\"Quantum embeddings shape: {quantum_embeddings.shape}\")\n\n# Load predictions and true values\npreds = np.load(f\"{model_name}_predictions.npz\")\ntrain_pred = preds['train_pred']\ntrain_true = preds['train_true']\nval_pred   = preds['val_pred']\nval_true   = preds['val_true']\ntest_pred  = preds['test_pred']\ntest_true  = preds['test_true']\n\n# Load hyperparameters (optional)\nwith open(f\"{model_name}_params.txt\", 'r') as f:\n    params = f.read()\nprint(\"Hyperparameters:\\n\", params)","metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"Analyzing experiment: qnn_q14_l12_b64_acc2_s42_20260228_115810_best\n"},{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'qnn_q14_l12_b64_acc2_s42_20260228_115810_best_embeddings.npz'","output_type":"error","traceback":["\u001b[31m---------------------------------------------------------------------------\u001b[39m","\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)","\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAnalyzing experiment: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Load the saved data\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m embeddings = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m_embeddings.npz\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m train_emb = embeddings[\u001b[33m'\u001b[39m\u001b[33mtrain_emb\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     22\u001b[39m val_emb   = embeddings[\u001b[33m'\u001b[39m\u001b[33mval_emb\u001b[39m\u001b[33m'\u001b[39m]\n","\u001b[36mFile \u001b[39m\u001b[32m/srv/conda/envs/notebook/lib/python3.11/site-packages/numpy/lib/_npyio_impl.py:454\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[39m\n\u001b[32m    452\u001b[39m     own_fid = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m454\u001b[39m     fid = stack.enter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m    455\u001b[39m     own_fid = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    457\u001b[39m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n","\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'qnn_q14_l12_b64_acc2_s42_20260228_115810_best_embeddings.npz'"]}],"execution_count":1},{"id":"fe761514-6aeb-4168-a0b1-c0d6cf28475c","cell_type":"code","source":"# Load the original dataframe (same as in training)\nDRIVE_URL = \"https://drive.google.com/uc?id=1PS0eB8dx8VMzVvxNUc6wBzsMRkEKJjWI\"\ndf = pd.read_csv(DRIVE_URL)\n\n# You'll need the same scaler and feature list if you want to map indices\n# But for now, we need the reaction names and V_B, etc.\n# Load the reaction split (to know test/val/train indices)\nOUTDIR_BASE = \"mdn_70_10_20_optimized\"\ntrain_reacts = pd.read_csv(f\"{OUTDIR_BASE}/train_reactions.csv\")[\"Reaction\"].values\nval_reacts   = pd.read_csv(f\"{OUTDIR_BASE}/val_reactions.csv\")[\"Reaction\"].values\ntest_reacts  = pd.read_csv(f\"{OUTDIR_BASE}/test_reactions.csv\")[\"Reaction\"].values\n\ntrain_mask = df[\"Reaction\"].isin(train_reacts)\nval_mask   = df[\"Reaction\"].isin(val_reacts)\ntest_mask  = df[\"Reaction\"].isin(test_reacts)\n\n# For full dataset indices, we can use the mask to split later if needed\n\n# Load classical MDN ensemble data (for switch and regime labels)\nENSEMBLE_DIR = os.path.join(OUTDIR_BASE, \"ensembles_fast\")\nseed_dirs = sorted([os.path.join(ENSEMBLE_DIR, d) for d in os.listdir(ENSEMBLE_DIR) if d.startswith(\"seed_\")])\nall_seed_components = []\nfor seed_path in seed_dirs:\n    npz_path = os.path.join(seed_path, \"mdn_all_components.npz\")\n    if os.path.exists(npz_path):\n        data = np.load(npz_path)\n        all_seed_components.append({\"pi\": data[\"pi\"]})\nprint(\"Loaded classical MDN seeds:\", len(all_seed_components))\n\n# Also load one seed for regime labels (e.g., seed 42)\nseed_path = os.path.join(ENSEMBLE_DIR, \"seed_42\", \"mdn_all_components.npz\")\ndata_mdn = np.load(seed_path)\npi_mdn = data_mdn[\"pi\"]\ndominant_regime = np.argmax(pi_mdn, axis=1)\nprint(\"Dominant regime shape:\", dominant_regime.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"ed2da8a4-8e9e-4a3c-bd74-6ce4096656f0","cell_type":"code","source":"# Attach embeddings to dataframe (full dataset)\ndf_emb = df.copy()\nfor i in range(quantum_embeddings.shape[1]):\n    df_emb[f\"q_{i}\"] = quantum_embeddings[:, i]\n\n# Compute reaction-level mean embedding\nreaction_emb = df_emb.groupby(\"Reaction\")[[f\"q_{i}\" for i in range(quantum_embeddings.shape[1])]].mean().reset_index()\nprint(\"Reaction-level embedding shape:\", reaction_emb.shape)\n\n# Load reliable switch from classical MDN (reuse your earlier code)\ndef compute_switch_per_seed(df, pi_array):\n    # (same as your function)\n    df_temp = df.copy().reset_index(drop=True)\n    df_temp[\"dominant\"] = np.argmax(pi_array, axis=1)\n    switch_dict = {}\n    for reaction, sub in df_temp.groupby(\"Reaction\"):\n        sub = sub.sort_values(\"E c.m.\").reset_index(drop=True)\n        dom = sub[\"dominant\"].values\n        E_vals = sub[\"E c.m.\"].values\n        if len(dom) < 2:\n            continue\n        switch_energy = np.nan\n        for i in range(1, len(dom)):\n            if dom[i] != dom[i-1]:\n                switch_energy = E_vals[i]\n                break\n        if not np.isnan(switch_energy):\n            V_B = sub[\"V_B\"].iloc[0]\n            x_switch = switch_energy / V_B\n            switch_dict[reaction] = x_switch\n    return switch_dict\n\nseed_switch_results = [compute_switch_per_seed(df, seed[\"pi\"]) for seed in all_seed_components]\n\nall_reactions = df[\"Reaction\"].unique()\nswitch_records = []\nfor reaction in all_reactions:\n    x_list = [sd[reaction] for sd in seed_switch_results if reaction in sd]\n    if len(x_list) > 0:\n        switch_records.append({\n            \"Reaction\": reaction,\n            \"x_switch_mean\": np.mean(x_list),\n            \"x_switch_std\": np.std(x_list),\n            \"seed_fraction\": len(x_list)/len(seed_switch_results)\n        })\nswitch_df = pd.DataFrame(switch_records)\nswitch_df_clean = switch_df[switch_df[\"seed_fraction\"] >= 0.8].copy()\nprint(\"Reliable switches:\", len(switch_df_clean))\n\n# Merge with reaction embeddings\nmerged = reaction_emb.merge(switch_df_clean[[\"Reaction\",\"x_switch_mean\"]], on=\"Reaction\", how=\"inner\")\nprint(\"Merged shape:\", merged.shape)\n\n# Quantum matrix\nQ_mat = merged[[f\"q_{i}\" for i in range(quantum_embeddings.shape[1])]].values\nx_vals = merged[\"x_switch_mean\"].values\n\n# PCA on reaction-level embeddings\npca = PCA(n_components=3)\nQ_pca = pca.fit_transform(Q_mat)\nprint(\"Explained variance ratio:\", pca.explained_variance_ratio_)\n\n# Correlate PC1 with x_switch\npc1 = Q_pca[:,0]\ncorr, pval = pearsonr(pc1, x_vals)\nprint(f\"PC1 vs x_switch: r={corr:.3f}, p={pval:.3e}\")\n\n# Plot\nplt.figure(figsize=(6,5))\nplt.scatter(pc1, x_vals, alpha=0.7)\nplt.xlabel(\"Quantum PC1\")\nplt.ylabel(\"x_switch\")\nplt.title(f\"{model_name}\\nPC1 vs x_switch (r={corr:.3f})\")\nplt.grid(alpha=0.3)\nplt.savefig(f\"{model_name}_pc1_vs_switch.png\", dpi=150)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"e2f623c0-7b31-44aa-addb-14f7f187660f","cell_type":"code","source":"# Merge structural parameters\nstruct_df = df.groupby(\"Reaction\").first().reset_index()\nmerged = merged.merge(struct_df[[\"Reaction\", \"β P\", \"β T\", \"Q ( 2 n )\"]], on=\"Reaction\", how=\"left\")\nmerged[\"beta_eff\"] = merged[\"β P\"].abs() + merged[\"β T\"].abs()\n\nbeta_vals = merged[\"beta_eff\"].values\nQ2n_vals = merged[\"Q ( 2 n )\"].values\n\nprint(\"PC1 vs beta_eff:\", pearsonr(pc1, beta_vals))\nprint(\"PC1 vs Q(2n):\", pearsonr(pc1, Q2n_vals))\n\n# Linear models\nX_pcs = Q_pca[:, :3]\nlr_pcs = LinearRegression().fit(X_pcs, x_vals)\nprint(\"R2 (3 PCs → x_switch):\", r2_score(x_vals, lr_pcs.predict(X_pcs)))\n\nX_struct = np.column_stack([beta_vals, Q2n_vals])\nlr_struct = LinearRegression().fit(X_struct, x_vals)\nprint(\"R2 (β_eff+Q2n → x_switch):\", r2_score(x_vals, lr_struct.predict(X_struct)))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"1f9d20e8-7312-4203-991e-70536bbe63bc","cell_type":"code","source":"# Use the full quantum embeddings and the MDN regime labels (from seed 42)\npca_sample = PCA(n_components=3)\nQ_pca_sample = pca_sample.fit_transform(quantum_embeddings)\nprint(\"Explained variance ratio:\", pca_sample.explained_variance_ratio_)\n\npca_df = pd.DataFrame({\n    \"PC1\": Q_pca_sample[:, 0],\n    \"PC2\": Q_pca_sample[:, 1],\n    \"Regime\": dominant_regime\n})\n\nplt.figure(figsize=(8,6))\nfor regime in np.unique(dominant_regime):\n    subset = pca_df[pca_df[\"Regime\"] == regime]\n    plt.scatter(subset[\"PC1\"], subset[\"PC2\"], alpha=0.4, label=f\"Regime {regime}\")\nplt.xlabel(\"PC1\")\nplt.ylabel(\"PC2\")\nplt.title(f\"{model_name}\\nQuantum PCA Colored by MDN Regime\")\nplt.legend()\nplt.grid(alpha=0.3)\nplt.savefig(f\"{model_name}_pca_regimes.png\", dpi=150)\nplt.show()\n\n# Classification accuracy using PC1 only\nclf = LogisticRegression(max_iter=1000)\nclf.fit(Q_pca_sample[:, 0].reshape(-1,1), dominant_regime)\nacc = accuracy_score(dominant_regime, clf.predict(Q_pca_sample[:, 0].reshape(-1,1)))\nprint(f\"Regime classification accuracy (PC1 only): {acc:.3f}\")\n\n# ANOVA\ngroups = [Q_pca_sample[dominant_regime == r, 0] for r in np.unique(dominant_regime)]\nf_stat, p_val = f_oneway(*groups)\nprint(f\"ANOVA PC1 across regimes: F={f_stat:.1f}, p={p_val:.3e}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"8f75d575-cd95-44cd-beff-792357916c18","cell_type":"code","source":"# Pairwise quantum distances vs |Δ x_switch|\n# (You can reuse your earlier code, but now at reaction level)\n# This may be redundant with PC1 correlation, but included for completeness.","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"b1ae808f-5d87-450f-a0ef-6c9e464ae0ce","cell_type":"code","source":"# Save merged reaction data with PCs and structural params\nmerged.to_csv(f\"{model_name}_reaction_analysis.csv\", index=False)\n\n# Save sample PCA data\nnp.savez(f\"{model_name}_sample_pca.npz\",\n         pc_scores=Q_pca_sample,\n         explained_ratio=pca_sample.explained_variance_ratio_)\n\nprint(\"All analysis results saved.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}